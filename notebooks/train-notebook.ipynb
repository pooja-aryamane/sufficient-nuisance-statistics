{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m \n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrain_gdro\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'train'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "import torch \n",
    "import os \n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "import shutil\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score\n",
    "\n",
    "from dataloader import * \n",
    "from models import * \n",
    "from train import * \n",
    "from train_gdro import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 /scratch/paa9751/mlhc-project/BalancingGroups/train-stage1-diff-loader.py --data_path /scratch/paa9751/mlhc-project/new_data --output_dir mnli_out --num_hparams_seeds 1 --num_init_seeds 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python3 train-duplicate.py --PROJECT_NAME 'stage-1-training-sample-split' --BORDER_SZ 25 --LEARNING_RATE 1e-4 --BATCH_SIZE 128 --WEIGHT_DECAY 1e-3 --MODEL_TYPE 'resnet18' --OUTDIR out-nuisance-samplesplit --MAX_EPOCHS 200 --SPLIT_IDX 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpooja-aryamane\u001b[0m (\u001b[33msuff-nuisance-stats\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/scratch/paa9751/mlhc-project/wandb/run-20240424_195644-catqbvxy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgroups_4_0.001+pretrained_False+batchsize_256+lr_0.0001_transformation_True\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/suff-nuisance-stats/stage-2-truegroups\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/suff-nuisance-stats/stage-2-truegroups/runs/catqbvxy\u001b[0m\n",
      "training started\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "train loss = 0, group 0 -  0.6211135745048523\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "train loss = 0, group 1 -  0.5595654449679635\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "train loss = 0, group 2 -  0.6688700199127198\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "train loss = 0, group 3 -  0.614042087576606\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "val loop\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "WORST GROUP ACCURACY =  0.6311111111111111\n",
      "0.6311111111111111\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "train loss = 1, group 0 -  0.5459889753298326\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "train loss = 1, group 1 -  0.5013062016530471\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "train loss = 1, group 2 -  0.6032401615923101\n",
      "train loss = 1, group 3 -  0.5466023206710815\n",
      "val loop\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "WORST GROUP ACCURACY =  0.6162962962962963\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "train loss = 2, group 0 -  0.5017061206427488\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "train loss = 2, group 1 -  0.44502244076945563\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "train loss = 2, group 2 -  0.5606704278425737\n",
      "train loss = 2, group 3 -  0.5011186746033756\n",
      "val loop\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "WORST GROUP ACCURACY =  0.4837037037037037\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "train loss = 3, group 0 -  0.4674298205158927\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "train loss = 3, group 1 -  0.41471023830500514\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "train loss = 3, group 2 -  0.5418688508597287\n",
      "train loss = 3, group 3 -  0.47378565045920285\n",
      "val loop\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "WORST GROUP ACCURACY =  0.662962962962963\n",
      "0.662962962962963\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "train loss = 4, group 0 -  0.4759922813285481\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "train loss = 4, group 1 -  0.3880826167084954\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "train loss = 4, group 2 -  0.48986140218648044\n",
      "train loss = 4, group 3 -  0.4115756358612667\n",
      "val loop\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "WORST GROUP ACCURACY =  0.6666666666666666\n",
      "0.6666666666666666\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "train loss = 5, group 0 -  0.4590087587183172\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "train loss = 5, group 1 -  0.3680254795334556\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "train loss = 5, group 2 -  0.4660293893380599\n",
      "train loss = 5, group 3 -  0.37758021368221806\n",
      "val loop\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "WORST GROUP ACCURACY =  0.68\n",
      "0.68\n",
      "/ext3/miniconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/IPython/utils/_process_posix.py:153\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# res is the index of the pattern that caused the match, so we\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# know whether we've finished (if we matched EOF) or not\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     res_idx \u001b[38;5;241m=\u001b[39m child\u001b[38;5;241m.\u001b[39mexpect_list(patterns, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_timeout)\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mprint\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore[out_size:]\u001b[38;5;241m.\u001b[39mdecode(enc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/pexpect/spawnbase.py:372\u001b[0m, in \u001b[0;36mSpawnBase.expect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exp\u001b[38;5;241m.\u001b[39mexpect_loop(timeout)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/pexpect/expect.py:169\u001b[0m, in \u001b[0;36mExpecter.expect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Still have time left, so read more data\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m incoming \u001b[38;5;241m=\u001b[39m spawn\u001b[38;5;241m.\u001b[39mread_nonblocking(spawn\u001b[38;5;241m.\u001b[39mmaxread, timeout)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspawn\u001b[38;5;241m.\u001b[39mdelayafterread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/pexpect/pty_spawn.py:500\u001b[0m, in \u001b[0;36mspawn.read_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Because of the select(0) check above, we know that no data\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# is available right now. But if a non-zero timeout is given\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# (possibly timeout=None), we call select() with a timeout.\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (timeout \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m select(timeout):\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(spawn, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mread_nonblocking(size)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/pexpect/pty_spawn.py:450\u001b[0m, in \u001b[0;36mspawn.read_nonblocking.<locals>.select\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(timeout):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m select_ignore_interrupts([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchild_fd], [], [], timeout)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/pexpect/utils.py:143\u001b[0m, in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m select\u001b[38;5;241m.\u001b[39mselect(iwtd, owtd, ewtd, timeout)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython3 train_gdro.py --LEARNING_RATE 1e-4 --BATCH_SIZE 256 --K 10000 --MODEL_TYPE \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresnet18\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m --WEIGHT_DECAY 1e-3 --OUTDIR \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstage2-outdir\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m --GROUP_CNAME \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue_group_idx\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m --n_groups 4 --PROJECT_NAME \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstage-2-truegroups\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m --TRANSFORM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py:655\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 655\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_expand(cmd, depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/IPython/utils/_process_posix.py:164\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    159\u001b[0m         out_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# We need to send ^C to the process.  The ascii code for '^C' is 3\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# (the character is known as ETX for 'End of Text', see\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# curses.ascii.ETX).\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m     child\u001b[38;5;241m.\u001b[39msendline(\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# Read and print any more output the program might produce on its\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# way out.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/pexpect/pty_spawn.py:578\u001b[0m, in \u001b[0;36mspawn.sendline\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Wraps send(), sending string ``s`` to child process, with\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;124;03m``os.linesep`` automatically appended. Returns number of bytes\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;124;03mwritten.  Only a limited number of bytes may be sent for each\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;124;03mline in the default terminal mode, see docstring of :meth:`send`.\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    577\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coerce_send_string(s)\n\u001b[0;32m--> 578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(s \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinesep)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.11/site-packages/pexpect/pty_spawn.py:563\u001b[0m, in \u001b[0;36mspawn.send\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Sends string ``s`` to the child process, returning the number of\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;124;03mbytes written. If a logfile is specified, a copy is written to that\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;124;03mlog.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;124;03m    >>> bash.sendline('x' * 5000)\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelaybeforesend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 563\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelaybeforesend)\n\u001b[1;32m    565\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coerce_send_string(s)\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log(s, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msend\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "!python3 train_gdro.py --LEARNING_RATE 1e-4 --BATCH_SIZE 256 --K 10000 --MODEL_TYPE 'resnet18' --WEIGHT_DECAY 1e-3 --OUTDIR 'stage2-outdir' --GROUP_CNAME 'true_group_idx' --n_groups 4 --PROJECT_NAME 'stage-2-truegroups' --TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_LABEL='negbio'\n",
    "IMAGE_SIZE=256\n",
    "TRANSFORM=False\n",
    "NWORKERS=6\n",
    "BATCH_SIZE=12\n",
    "BORDER_SZ=0\n",
    "K=10000\n",
    "MAX_EPOCHS=100\n",
    "LEARNING_RATE=1e-3\n",
    "WEIGHT_DECAY=0\n",
    "LOGFILE=\"./logs-ntbk\"\n",
    "OUTDIR=\"./out-ntbk\"\n",
    "MODEL_TYPE=\"resnet18\"\n",
    "PRETRAINED=False\n",
    "RESIZE=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoneTransform(object):\n",
    "    \"\"\" Does nothing to the image, to be used instead of None\n",
    "    \n",
    "    Args:\n",
    "        image in, image out, nothing is done\n",
    "    \"\"\"\n",
    "    def __call__(self, image):  \n",
    "        return image\n",
    "\n",
    "image_transformation = [NoneTransform(),\n",
    "                    transforms.ElasticTransform(alpha=250.0), \n",
    "                    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5.)), \n",
    "                    transforms.RandomHorizontalFlip(p=0.5), \n",
    "                    transforms.RandomVerticalFlip(p=0.5), \n",
    "                    transforms.RandomRotation(degrees=(0, 180))]\n",
    "trans = transforms.RandomChoice(image_transformation, [0.5, 0.1,0.1,0.1,0.1,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transformation = [NoneTransform(),\n",
    "                    transforms.ElasticTransform(alpha=250.0), \n",
    "                    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5.)), \n",
    "                    transforms.RandomHorizontalFlip(p=0.5), \n",
    "                    transforms.RandomVerticalFlip(p=0.5), \n",
    "                    transforms.RandomRotation(degrees=(0, 180))]\n",
    "trans = transforms.RandomChoice(image_transformation, [0.5, 0.1,0.1,0.1,0.1,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans(batch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chexpert_dir = '/scratch/paa9751/mlhc-project/resized_data/chexpert'\n",
    "mimic_dir = '/scratch/paa9751/mlhc-project/resized_data/mimic'\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "#     train_dataloader, val_dataloader, test_dataloader = load_combined_data(chexpert_dir, (mimic_dir, M_LABEL), IMAGE_SIZE, TRANSFORM, NWORKERS, BATCH_SIZE, BORDER_SZ, K)  \n",
    "\n",
    "NORMALISE=True\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = load_resized_data(chexpert_dir, mimic_dir, IMAGE_SIZE, False, True, NWORKERS, BATCH_SIZE, BORDER_SZ, 'true_group_idx', 0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_MEAN = [0.445,0.445]         # Mean of ImageNet dataset (used for normalization)\n",
    "IMAGENET_STD = [0.269,0.269]\n",
    "norm = transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_dataloader:\n",
    "    path = i[0]\n",
    "    batch_x = i[1]\n",
    "    batch_y= i[2]\n",
    "    group = i[3]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = np.load(path[0])\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = torch.from_numpy(img_data)\n",
    "img_tensor = img_tensor.unsqueeze(0)\n",
    "img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(batch_x - 0.445) / 0.269"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = batch_x[0][0]\n",
    "# (sample==0).sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[25:-25, 25:-25].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sample==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_training_robust(model, train_dataloader, val_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions: \n",
    "def compute_group_avg(losses, group_idx):\n",
    "    # compute observed counts and mean loss for each group\n",
    "    n_groups = torch.unique(group_idx).shape[0]\n",
    "    group_map = (group_idx == torch.arange(n_groups).unsqueeze(1).long()).float()\n",
    "    group_count = group_map.sum(1)\n",
    "    group_denom = group_count + (group_count==0).float() # avoid nans\n",
    "    group_loss = (group_map @ losses.view(-1))/group_denom #check loss dim \n",
    "    return group_loss, group_count\n",
    "\n",
    "def compute_robust_loss(group_probs, step_size, group_loss): \n",
    "    #they either normalise group loss or adjust group loss by adding adj/sqrt(count)\n",
    "    group_probs = group_probs * torch.exp(step_size * group_loss)\n",
    "    group_probs = group_probs/group_probs.sum()\n",
    "    robust_loss = group_loss @ group_probs\n",
    "    return robust_loss, group_probs.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_LABEL='negbio'\n",
    "IMAGE_SIZE=256\n",
    "TRANSFORM=False\n",
    "NWORKERS=6\n",
    "BATCH_SIZE=12\n",
    "BORDER_SZ=0\n",
    "K=10000\n",
    "MAX_EPOCHS=100\n",
    "LEARNING_RATE=1e-3\n",
    "WEIGHT_DECAY=0\n",
    "LOGFILE=\"./logs-ntbk\"\n",
    "OUTDIR=\"./out-ntbk/out-erm\"\n",
    "MODEL_TYPE=\"resnet18\"\n",
    "PRETRAINED=False\n",
    "RESIZE=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_training( model, train_dataloader, val_dataloader, device):\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-2)\n",
    "   # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    training_losses=[]\n",
    "    validation_losses=[]\n",
    "    validation_accuracy=[]\n",
    "    #validation_metrics={}\n",
    "\n",
    "    auroc_metric = BinaryAUROC(thresholds=None)\n",
    "    f1_metric = BinaryF1Score()\n",
    "    print(\"training started\")\n",
    "    for epoch in range(MAX_EPOCHS): \n",
    "        #print('training started.')\n",
    "        #train model \n",
    "        model.train()\n",
    "        train_loss=0\n",
    "        for batch_x, batch_y,l in train_dataloader: #16, 100, 512, 512 \n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            pred = model(batch_x.float())\n",
    "            pred = pred.squeeze(1)\n",
    "            loss = criterion(pred, batch_y.float()) \n",
    "            train_loss+=loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print('iteration done')\n",
    "            \n",
    "        #print(f'epoch {epoch}, train done')\n",
    "\n",
    "        train_loss = train_loss/len(train_dataloader)\n",
    "        training_losses.append(train_loss)\n",
    "\n",
    "        val_loss=0\n",
    "        correct=0\n",
    "        total=0\n",
    "        all_preds=[]\n",
    "        all_labels=[]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            sigmoid = torch.nn.Sigmoid()\n",
    "            for batch_x, batch_y,l in val_dataloader:\n",
    "                batch_x = batch_x.to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "                pred = model(batch_x.float()).squeeze(1)\n",
    "                predicted = (sigmoid(pred)>0.5).float()\n",
    "                correct += (predicted == batch_y).sum().item() \n",
    "                total+=batch_y.size(0)\n",
    "                loss = criterion(pred, batch_y.float()) \n",
    "                val_loss += loss.item()\n",
    "                all_preds.append(pred.cpu())\n",
    "                all_labels.append(batch_y.cpu())\n",
    "\n",
    "            val_loss = val_loss / len(val_dataloader)\n",
    "            val_acc = correct / total \n",
    "            validation_losses.append(val_loss)\n",
    "            validation_accuracy.append(val_acc)\n",
    "            val_f1 = f1_metric(torch.cat(all_preds,0), torch.cat(all_labels,0))\n",
    "            val_auroc = auroc_metric(torch.cat(all_preds,0), torch.cat(all_labels,0))\n",
    "\n",
    "        #if (epoch+1)%10 == 0: \n",
    "        #logging.info(f\"Epoch {epoch+1} : Training loss = {train_loss}, Val loss = {val_loss}, Val Acc = {val_acc}, Val AUROC = {val_auroc}, Val F1 = {val_f1}\")\n",
    "        print(f\"Epoch {epoch+1} : Training loss = {train_loss}, Val loss = {val_loss}, Val Acc = {val_acc}, Val AUROC = {val_auroc}, Val F1 = {val_f1}\")\n",
    "\n",
    "        if (epoch+1)%10 == 0:\n",
    "            print('training works')\n",
    "            torch.save(model, f'{OUTDIR}/{str(BORDER_SZ) + MODEL_TYPE + str(PRETRAINED) + str(BATCH_SIZE)}_model_{epoch+1}.pth')\n",
    "\n",
    "        #before_lr = optimizer.param_groups[0][\"lr\"]\n",
    "        #scheduler.step()\n",
    "        #after_lr = optimizer.param_groups[0][\"lr\"]\n",
    "        #logging.info(\"Epoch %d: Exponential lr %.4f -> %.4f\" % (epoch, before_lr, after_lr))\n",
    "    \n",
    "            np.save(f'{OUTDIR}/{str(epoch+1)+str(BORDER_SZ) + str(LEARNING_RATE) + str(BATCH_SIZE)}_training_losses.npy', np.array(training_losses))\n",
    "            np.save(f'{OUTDIR}/{str(epoch+1)+str(BORDER_SZ) + str(LEARNING_RATE) + str(BATCH_SIZE)}_validation_losses.npy', np.array(validation_losses))\n",
    "            np.save(f'{OUTDIR}/{str(epoch+1)+str(BORDER_SZ) + str(LEARNING_RATE) + str(BATCH_SIZE)}_validation_accuracy.npy', np.array(validation_accuracy))\n",
    "\n",
    "    torch.save(model, f'{OUTDIR}/final_model.pth')\n",
    "    print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_training( model, train_dataloader, val_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgeo",
   "language": "python",
   "name": "pytorch-example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
